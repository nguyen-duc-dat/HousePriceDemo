{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nILUXXHoU_1",
        "outputId": "ad5d6dee-e335-42cf-fa5b-77897eba2bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# --- 1. K·∫æT N·ªêI GOOGLE DRIVE (ƒê·ªÉ l·∫•y d·ªØ li·ªáu) ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlBAu5QYrwLf",
        "outputId": "1d18f93e-1992-4f69-8631-b8d9bac17b10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD D·ªÆ LI·ªÜU ƒê·∫¶U V√ÄO (DATA LOADING)\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# 1. Kh·ªüi t·∫°o Spark\n",
        "spark = SparkSession.builder.appName(\"DS_Model\").getOrCreate()\n",
        "\n",
        "# 2. ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n chung\n",
        "base_path = \"/content/drive/MyDrive/dulieulon/BTL\"\n",
        "parquet_path = f\"{base_path}/processed_house_data.parquet\"\n",
        "csv_path = f\"{base_path}/zipcode_coords.csv\"\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# PH·∫¶N A: ƒê·ªåC D·ªÆ LI·ªÜU CH√çNH (PARQUET)\n",
        "# ------------------------------------------------------------------------------\n",
        "try:\n",
        "    df_house = spark.read.parquet(parquet_path)\n",
        "    print(f\"‚úÖ [1/2] T·∫£i th√†nh c√¥ng D·ªØ li·ªáu Nh√† (Parquet)!\")\n",
        "    print(f\"   -> T·ªïng s·ªë d√≤ng: {df_house.count():,}\")\n",
        "    df_house.printSchema()\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå L·ªói ƒë·ªçc Parquet: {e}\")\n",
        "\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# PH·∫¶N B: ƒê·ªåC D·ªÆ LI·ªÜU ZIPCODE (CSV)\n",
        "# ------------------------------------------------------------------------------\n",
        "try:\n",
        "    # L∆∞u √Ω: V·ªõi CSV ph·∫£i c√≥ header=True ƒë·ªÉ n√≥ hi·ªÉu d√≤ng ƒë·∫ßu l√† t√™n c·ªôt\n",
        "    df_zip = spark.read.csv(csv_path, header=True, inferSchema=True)\n",
        "    print(f\"‚úÖ [2/2] T·∫£i th√†nh c√¥ng D·ªØ li·ªáu Zipcode (CSV)!\")\n",
        "    print(f\"   -> T·ªïng s·ªë Zipcode: {df_zip.count()}\")\n",
        "\n",
        "    # In th·ª≠ v√†i d√≤ng xem t·ªça ƒë·ªô ƒë√∫ng ch∆∞a\n",
        "    print(\"   -> M·∫´u d·ªØ li·ªáu:\")\n",
        "    df_zip.show(3)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå L·ªói ƒë·ªçc CSV: {e}\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\" D·ªÆ LI·ªÜU ƒê√É S·∫¥N S√ÄNG ƒê·ªÇ TRAIN MODEL!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyaO-3fmrtrc",
        "outputId": "fdd7744a-253c-4ef7-9d40-b17f3b686aa8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ [1/2] T·∫£i th√†nh c√¥ng D·ªØ li·ªáu Nh√† (Parquet)!\n",
            "   -> T·ªïng s·ªë d√≤ng: 21,596\n",
            "root\n",
            " |-- price: double (nullable = true)\n",
            " |-- bedrooms: integer (nullable = true)\n",
            " |-- bathrooms: double (nullable = true)\n",
            " |-- sqft_living: double (nullable = true)\n",
            " |-- sqft_lot: integer (nullable = true)\n",
            " |-- floors: double (nullable = true)\n",
            " |-- waterfront: integer (nullable = true)\n",
            " |-- view: integer (nullable = true)\n",
            " |-- condition: integer (nullable = true)\n",
            " |-- grade: integer (nullable = true)\n",
            " |-- sqft_above: integer (nullable = true)\n",
            " |-- sqft_basement: integer (nullable = true)\n",
            " |-- yr_built: integer (nullable = true)\n",
            " |-- yr_renovated: integer (nullable = true)\n",
            " |-- zipcode: integer (nullable = true)\n",
            " |-- lat: double (nullable = true)\n",
            " |-- long: double (nullable = true)\n",
            " |-- sqft_living15: integer (nullable = true)\n",
            " |-- sqft_lot15: integer (nullable = true)\n",
            " |-- sell_month: integer (nullable = true)\n",
            "\n",
            "------------------------------\n",
            "‚úÖ [2/2] T·∫£i th√†nh c√¥ng D·ªØ li·ªáu Zipcode (CSV)!\n",
            "   -> T·ªïng s·ªë Zipcode: 70\n",
            "   -> M·∫´u d·ªØ li·ªáu:\n",
            "+-------+-----------------+-------------------+\n",
            "|zipcode|       center_lat|        center_long|\n",
            "+-------+-----------------+-------------------+\n",
            "|  98002|47.30877989949747|-122.21335678391958|\n",
            "|  98155|47.75486322869954|-122.30354035874457|\n",
            "|  98198|47.39078785714286|-122.31574285714284|\n",
            "+-------+-----------------+-------------------+\n",
            "only showing top 3 rows\n",
            "==================================================\n",
            " D·ªÆ LI·ªÜU ƒê√É S·∫¥N S√ÄNG ƒê·ªÇ TRAIN MODEL!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chu·∫©n b·ªã d·ªØ li·ªáu"
      ],
      "metadata": {
        "id": "negLOdFg08UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 1: SETUP & DATA PREP ---\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import pandas as pd\n",
        "\n",
        "# 1. ƒê·ªãnh nghƒ©a c√°c bi·∫øn ƒë·∫ßu v√†o (Features)\n",
        "feature_cols = [\n",
        "    'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
        "    'waterfront', 'view', 'condition', 'grade',\n",
        "    'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
        "    'lat', 'long', 'sqft_living15', 'sqft_lot15', 'sell_month'\n",
        "]\n",
        "\n",
        "# 2. Vector Assembler (Gom c·ªôt)\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "# 3. Chia t·∫≠p d·ªØ li·ªáu (80% Train - 20% Test)\n",
        "train_data, test_data = df_house.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"‚úÖ ƒê√£ chia d·ªØ li·ªáu xong!\")\n",
        "print(f\"   - T·∫≠p hu·∫•n luy·ªán (Train): {train_data.count():,} d√≤ng\")\n",
        "print(f\"   - T·∫≠p ki·ªÉm tra (Test): {test_data.count():,} d√≤ng\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReaiJK6O1Acn",
        "outputId": "bc1b2011-9012-48d4-df19-3533756ec54f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ƒê√£ chia d·ªØ li·ªáu xong!\n",
            "   - T·∫≠p hu·∫•n luy·ªán (Train): 17,334 d√≤ng\n",
            "   - T·∫≠p ki·ªÉm tra (Test): 4,262 d√≤ng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ch·∫°y LINEAR REGRESSION\n",
        "√Åp d·ª•ng Grid Search ƒë·ªÉ t√¨m tham s·ªë ph·∫°t L1/L2 t·ªëi ∆∞u"
      ],
      "metadata": {
        "id": "UgCMaojy1UGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üöÄ ƒêANG CH·∫†Y LINEAR REGRESSION (ELASTIC NET)...\")\n",
        "print(\"   (ƒêang d√≤ t√¨m tham s·ªë ph·∫°t regParam v√† elasticNetParam t·ªët nh·∫•t...)\")\n",
        "\n",
        "# 1. Kh·ªüi t·∫°o\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"price\")\n",
        "lr_pipeline = Pipeline(stages=[assembler, lr])\n",
        "\n",
        "# 2. T·∫°o l∆∞·ªõi tham s·ªë (Grid Search)\n",
        "lr_paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.regParam, [0.0, 0.01, 0.1, 0.5]) \\\n",
        "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .build()\n",
        "\n",
        "# 3. Cross Validation\n",
        "lr_crossval = CrossValidator(estimator=lr_pipeline,\n",
        "                             estimatorParamMaps=lr_paramGrid,\n",
        "                             evaluator=RegressionEvaluator(labelCol=\"price\", metricName=\"rmse\"),\n",
        "                             numFolds=3)\n",
        "\n",
        "# 4. Train & Evaluate\n",
        "lr_cv_model = lr_crossval.fit(train_data)\n",
        "lr_predictions = lr_cv_model.transform(test_data)\n",
        "\n",
        "# ƒê√°nh gi√°\n",
        "eval_rmse = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "eval_r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "rmse_lr = eval_rmse.evaluate(lr_predictions)\n",
        "r2_lr = eval_r2.evaluate(lr_predictions)\n",
        "best_lr = lr_cv_model.bestModel.stages[-1]\n",
        "\n",
        "print(f\"‚úÖ K·∫æT QU·∫¢ LINEAR REGRESSION:\")\n",
        "print(f\"   - R2 Score: {r2_lr:.4f}\")\n",
        "print(f\"   - RMSE: ${rmse_lr:,.0f}\")\n",
        "print(f\"   - Tham s·ªë t·ªëi ∆∞u: regParam={best_lr.getRegParam()} | elasticNetParam={best_lr.getElasticNetParam()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhAyaE-g1Ogj",
        "outputId": "4f534aa8-016b-4434-febf-a786108de956"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ [1/3] ƒêANG CH·∫†Y LINEAR REGRESSION (ELASTIC NET)...\n",
            "   (ƒêang d√≤ t√¨m tham s·ªë ph·∫°t regParam v√† elasticNetParam t·ªët nh·∫•t...)\n",
            "‚úÖ K·∫æT QU·∫¢ LINEAR REGRESSION:\n",
            "   - R2 Score: 0.6750\n",
            "   - RMSE: $207,632\n",
            "   - Tham s·ªë t·ªëi ∆∞u: regParam=0.5 | elasticNetParam=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANDOM FOREST"
      ],
      "metadata": {
        "id": "_XHb1bfL1t3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nƒêANG CH·∫†Y RANDOM FOREST (TUNING)...\")\n",
        "\n",
        "# 1. Kh·ªüi t·∫°o\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"price\", seed=42)\n",
        "rf_pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# 2. T·∫°o l∆∞·ªõi tham s·ªë (Grid Search)\n",
        "rf_paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(rf.numTrees, [20, 50, 100]) \\\n",
        "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
        "    .build()\n",
        "\n",
        "# 3. Cross Validation\n",
        "rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
        "                             estimatorParamMaps=rf_paramGrid,\n",
        "                             evaluator=eval_rmse,\n",
        "                             numFolds=3)\n",
        "\n",
        "# 4. Train & Evaluate\n",
        "rf_cv_model = rf_crossval.fit(train_data)\n",
        "rf_predictions = rf_cv_model.transform(test_data)\n",
        "\n",
        "rmse_rf = eval_rmse.evaluate(rf_predictions)\n",
        "r2_rf = eval_r2.evaluate(rf_predictions)\n",
        "best_rf = rf_cv_model.bestModel.stages[-1]\n",
        "\n",
        "print(f\"‚úÖ K·∫æT QU·∫¢ RANDOM FOREST:\")\n",
        "print(f\"   - R2 Score: {r2_rf:.4f}\")\n",
        "print(f\"   - RMSE: ${rmse_rf:,.0f}\")\n",
        "print(f\"   - Tham s·ªë t·ªëi ∆∞u: NumTrees={best_rf.getNumTrees} | MaxDepth={best_rf.getOrDefault('maxDepth')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu-LdyRq10zZ",
        "outputId": "cad39574-c362-4ee1-b218-ee713b59e45f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄƒêANG CH·∫†Y RANDOM FOREST (TUNING)...\n",
            "‚úÖ K·∫æT QU·∫¢ RANDOM FOREST:\n",
            "   - R2 Score: 0.8659\n",
            "   - RMSE: $133,353\n",
            "   - Tham s·ªë t·ªëi ∆∞u: NumTrees=100 | MaxDepth=15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# So s√°nh 2 m√¥ h√¨nh\n",
        "\n"
      ],
      "metadata": {
        "id": "lgMGZMbl27sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# T·∫°o DataFrame so s√°nh\n",
        "comparison_data = [\n",
        "    {\n",
        "        \"Model\": \"Linear Regression \",\n",
        "        \"R2 Score\": r2_lr,\n",
        "        \"RMSE ($)\": rmse_lr,\n",
        "        \"Ghi ch√∫\": \"M√¥ h√¨nh c∆° s·ªü (Tuy·∫øn t√≠nh)\"\n",
        "    },\n",
        "    {\n",
        "        \"Model\": \"Random Forest\",\n",
        "        \"R2 Score\": r2_rf,\n",
        "        \"RMSE ($)\": rmse_rf,\n",
        "        \"Ghi ch√∫\": \"M√¥ h√¨nh n√¢ng cao (Phi tuy·∫øn t√≠nh)\"\n",
        "    }\n",
        "]\n",
        "\n",
        "df_compare = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(df_compare.to_string(index=False))\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Nh·∫≠n x√©t t·ª± ƒë·ªông\n",
        "diff_r2 = (r2_rf - r2_lr) * 100\n",
        "print(f\"üí° NH·∫¨N X√âT: Random Forest c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c th√™m {diff_r2:.2f}% so v·ªõi Linear Regression.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axpgRjnq4VzF",
        "outputId": "d5396e9f-8e20-4970-f92f-12afcee1850d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "             Model  R2 Score      RMSE ($)                           Ghi ch√∫\n",
            "Linear Regression   0.675018 207631.883070        M√¥ h√¨nh c∆° s·ªü (Tuy·∫øn t√≠nh)\n",
            "     Random Forest  0.865947 133352.878974 M√¥ h√¨nh n√¢ng cao (Phi tuy·∫øn t√≠nh)\n",
            "--------------------------------------------------------------------------------\n",
            "üí° NH·∫¨N X√âT: Random Forest c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c th√™m 19.09% so v·ªõi Linear Regression.\n"
          ]
        }
      ]
    }
  ]
}