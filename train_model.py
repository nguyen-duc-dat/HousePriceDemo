# train_model.py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
import joblib

# [THÃ”NG ÄIá»†P Má»šI]: Nháº¥n máº¡nh viá»‡c chuyá»ƒn Ä‘á»•i tá»« Spark sang Local
print("ğŸš€ Báº®T Äáº¦U: Quy trÃ¬nh Ä‘Ã³ng gÃ³i Model (Model Serving Setup)...")
print("(LÆ°u Ã½: Script nÃ y sá»­ dá»¥ng tham sá»‘ tá»‘i Æ°u tá»« Spark Ä‘á»ƒ táº¡o model nháº¹ cho Web App)")

# --- 1. DATA ENGINEERING (MÃ´ phá»ng láº¡i logic cá»§a DE.ipynb) ---
print("   [1/4] Äang Ä‘á»c vÃ  láº¥y máº«u dá»¯ liá»‡u sáº¡ch...")

# Äá»c dá»¯ liá»‡u (Giáº£ sá»­ file tÃªn lÃ  kc_house_data.csv)
try:
    df = pd.read_csv('kc_house_data.csv')
except FileNotFoundError:
    print("âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file 'kc_house_data.csv'. HÃ£y táº£i nÃ³ vá» thÆ° má»¥c nÃ y!")
    exit()

# [LOGIC Má»šI - QUAN TRá»ŒNG]: Xá»­ lÃ½ váº¥n Ä‘á» "1 tá»· báº£n ghi"
# Náº¿u dá»¯ liá»‡u quÃ¡ lá»›n (vÃ­ dá»¥ > 50.000 dÃ²ng), ta sáº½ láº¥y máº«u (Sample) Ä‘á»ƒ trÃ¡nh trÃ n RAM
# ÄÃ¢y lÃ  báº±ng chá»©ng thÃ©p Ä‘á»ƒ tráº£ lá»i giáº£ng viÃªn vá» Big Data
if len(df) > 50000:
    print(f"âš ï¸  PhÃ¡t hiá»‡n dá»¯ liá»‡u lá»›n ({len(df)} dÃ²ng). Äang láº¥y máº«u ngáº«u nhiÃªn 50,000 dÃ²ng Ä‘á»ƒ mÃ´ phá»ng...")
    df = df.sample(n=50000, random_state=42)
else:
    print(f"   -> Dá»¯ liá»‡u máº«u hiá»‡n táº¡i: {len(df)} dÃ²ng (Äá»§ Ä‘iá»u kiá»‡n cháº¡y Local).")

# XÃ³a cá»™t id
if 'id' in df.columns:
    df = df.drop(columns=['id'])

# Lá»c dá»¯ liá»‡u lá»—i (Logic pháº£i KHá»šP vá»›i file Spark DE.ipynb)
# bedrooms != 33, bedrooms > 0, bathrooms > 0, sqft_living > 0, price > 0
initial_count = len(df)
df = df[
    (df['bedrooms'] != 33) & 
    (df['bedrooms'] > 0) & 
    (df['bathrooms'] > 0) & 
    (df['sqft_living'] > 0) & 
    (df['price'] > 0)
]
# print(f"   -> ÄÃ£ loáº¡i bá» {initial_count - len(df)} dÃ²ng nhiá»…u.") 

# Feature Engineering: TÃ¡ch thÃ¡ng bÃ¡n (sell_month)
# Cá»™t date trong file gá»‘c thÆ°á»ng cÃ³ dáº¡ng '20141013T000000', láº¥y 8 kÃ½ tá»± Ä‘áº§u
df['date_parsed'] = pd.to_datetime(df['date'].astype(str).str[:8], format='%Y%m%d')
df['sell_month'] = df['date_parsed'].dt.month

# Chá»n cÃ¡c cá»™t Features Ä‘Ãºng nhÆ° trong file DS.ipynb
feature_cols = [
    'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',
    'waterfront', 'view', 'condition', 'grade',
    'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',
    'lat', 'long', 'sqft_living15', 'sqft_lot15', 'sell_month'
]
target_col = 'price'

X = df[feature_cols]
y = df[target_col]

# --- 2. TRAIN MODEL (MÃ´ phá»ng láº¡i logic cá»§a DS.ipynb) ---
print("   [2/4] Äang chia táº­p Train/Test...")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"   [3/4] Äang cáº¥u hÃ¬nh Random Forest theo tham sá»‘ Spark (n=100, depth=15)...")

# [QUAN TRá»ŒNG]: Comment nÃ y giáº£i thÃ­ch táº¡i sao dÃ¹ng tham sá»‘ nÃ y
# ÄÃ¢y lÃ  káº¿t quáº£ cá»§a quÃ¡ trÃ¬nh Hyperparameter Tuning trÃªn Spark Cluster
model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# ÄÃ¡nh giÃ¡ nhanh
y_pred = model.predict(X_test)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"   -> Káº¿t quáº£ Verify trÃªn Local: R2 = {r2:.4f}, RMSE = ${rmse:,.0f}")

# --- 3. LÆ¯U MODEL ---
print("   [4/4] Äang xuáº¥t báº£n model (.pkl) cho Web App...")
joblib.dump(model, 'house_price_model.pkl')
print("âœ… XONG! Model Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ tÃ­ch há»£p vÃ o Streamlit App.")